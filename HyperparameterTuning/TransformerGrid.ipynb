{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12ec09f6-98ca-4f9f-bcf3-a15501a34a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "import torch.nn.functional as F\n",
    "from early_stopping_pytorch import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "645150a9-11ba-412f-8570-99f06cf9f84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  2.1.1\n",
      "GPU Device Name:  Tesla V100-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "# Check PyTorch version\n",
    "print(\"PyTorch Version: \", torch.__version__)\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Device Name: \", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"No GPU available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82e96c42-8df0-4786-8915-5e1425993d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open('/scratch/da3245/datasets/timeseries_voltage/stratified_no_overlap.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_train = data['X_train']\n",
    "y_train = data['y_train']\n",
    "X_val = data['X_val']\n",
    "y_val = data['y_val']\n",
    "X_test = data['X_test']\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94700139-6b44-4d01-892e-3bf69ae6b577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (59233, 200)\n",
      "y_train shape: (59233, 200)\n",
      "X_val shape: (10453, 200)\n",
      "y_val shape: (10453, 200)\n",
      "X_test shape: (12298, 200)\n",
      "y_test shape: (12298, 200)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cf88ace-6883-40da-8819-62f455c62bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back to tensors for DataLoader\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(-1)  # Add channel dimension\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32).unsqueeze(-1)  \n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f7f5e16-b19e-4374-81a3-8242358d6dd8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TemporalConvNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m train_subset_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_subset_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m#Train and evaluate the model\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTemporalConvNet\u001b[49m(input_size, num_channels, kernel_size\u001b[38;5;241m=\u001b[39mkernel_size, dropout\u001b[38;5;241m=\u001b[39mdropout)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     57\u001b[0m f1 \u001b[38;5;241m=\u001b[39m train_and_evaluate(model, train_subset_loader, val_loader, test_loader, device)\n\u001b[1;32m     58\u001b[0m f1_scores\u001b[38;5;241m.\u001b[39mappend(f1)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TemporalConvNet' is not defined"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate(model, train_loader, val_loader, test_loader, device, num_epochs=50, lr=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_train_loss = 0.0\n",
    "        num_train_batches = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.view(-1, 2), labels.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_train_loss += loss.item()\n",
    "            num_train_batches += 1\n",
    "\n",
    "        train_losses.append(epoch_train_loss / num_train_batches)\n",
    "\n",
    "        model.eval()\n",
    "        epoch_val_loss = 0.0\n",
    "        num_val_batches = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device).permute(0, 2, 1)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs.view(-1, 2), labels.view(-1))\n",
    "                epoch_val_loss += loss.item()\n",
    "                num_val_batches += 1\n",
    "\n",
    "        val_losses.append(epoch_val_loss / num_val_batches)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}')\n",
    "    precision, recall, f1, auc = evaluate_model(model, test_loader, device)\n",
    "    return f1\n",
    "\n",
    "\n",
    "train_sizes = np.linspace(0.1, 1.0, 10)  # 10 steps from 10% to 100% of training data\n",
    "f1_scores = []\n",
    "for train_size in train_sizes:\n",
    "    num_train_samples = int(len(X_train) * train_size)\n",
    "    train_subset_indices = np.random.choice(len(X_train), num_train_samples, replace=False)\n",
    "    X_train_subset = X_train[train_subset_indices]\n",
    "    y_train_subset = y_train[train_subset_indices]\n",
    "\n",
    "    train_subset_dataset = TensorDataset(X_train_subset, y_train_subset)\n",
    "    train_subset_loader = DataLoader(train_subset_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    #Train and evaluate the model\n",
    "    model = TemporalConvNet(input_size, num_channels, kernel_size=kernel_size, dropout=dropout).to(device)\n",
    "    f1 = train_and_evaluate(model, train_subset_loader, val_loader, test_loader, device)\n",
    "    f1_scores.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ad89d51-20ab-4bd1-831f-088854fc3255",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AttentionLSTM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#model = SequenceLabelingRNN(input_size, hidden_size, num_layers, output_size, dropout_rate).to(device)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAttentionLSTM\u001b[49m(input_size, hidden_size, num_layers, output_size, dropout_rate)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      3\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AttentionLSTM' is not defined"
     ]
    }
   ],
   "source": [
    "#model = SequenceLabelingRNN(input_size, hidden_size, num_layers, output_size, dropout_rate).to(device)\n",
    "model = AttentionLSTM(input_size, hidden_size, num_layers, output_size, dropout_rate).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels[:,0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa2f5c0-a6df-43d6-9551-6e1f5e5d7576",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_size = 1\n",
    "#num_channels = [32, 64, 128]\n",
    "num_channels = [32, 64, 128, 256]\n",
    "kernel_size = 3\n",
    "dropout = 0.002\n",
    "\n",
    "model = TemporalConvNet(input_size, num_channels, kernel_size=kernel_size, dropout=dropout).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001,weight_decay=1e-4)\n",
    "early_stopping = EarlyStopping(patience=10, verbose=True) #https://github.com/Bjarten/early-stopping-pytorch\n",
    "\n",
    "#from torchinfo import summary\n",
    "#print(summary(model, input_size=(32,1,200))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78a90633-5b9f-4637-8a2e-608a771296ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.0327\n",
      "Epoch [1/50], Train Loss: 0.0109, Val Loss: 0.0136\n",
      "Validation loss decreased (inf --> 0.013646).  Saving model ...\n",
      "Epoch [2/50], Loss: 0.0044\n",
      "Epoch [2/50], Train Loss: 0.0122, Val Loss: 0.0133\n",
      "Validation loss decreased (0.013646 --> 0.013296).  Saving model ...\n",
      "Epoch [3/50], Loss: 0.0037\n",
      "Epoch [3/50], Train Loss: 0.0105, Val Loss: 0.0130\n",
      "Validation loss decreased (0.013296 --> 0.012979).  Saving model ...\n",
      "Epoch [4/50], Loss: 0.0260\n",
      "Epoch [4/50], Train Loss: 0.0102, Val Loss: 0.0128\n",
      "Validation loss decreased (0.012979 --> 0.012758).  Saving model ...\n",
      "Epoch [5/50], Loss: 0.0035\n",
      "Epoch [5/50], Train Loss: 0.0126, Val Loss: 0.0126\n",
      "Validation loss decreased (0.012758 --> 0.012550).  Saving model ...\n",
      "Epoch [6/50], Loss: 0.0076\n",
      "Epoch [6/50], Train Loss: 0.0126, Val Loss: 0.0128\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch [7/50], Loss: 0.0020\n",
      "Epoch [7/50], Train Loss: 0.0097, Val Loss: 0.0123\n",
      "Validation loss decreased (0.012550 --> 0.012301).  Saving model ...\n",
      "Epoch [8/50], Loss: 0.0028\n",
      "Epoch [8/50], Train Loss: 0.0113, Val Loss: 0.0121\n",
      "Validation loss decreased (0.012301 --> 0.012108).  Saving model ...\n",
      "Epoch [9/50], Loss: 0.0531\n",
      "Epoch [9/50], Train Loss: 0.0092, Val Loss: 0.0118\n",
      "Validation loss decreased (0.012108 --> 0.011822).  Saving model ...\n",
      "Epoch [10/50], Loss: 0.0119\n",
      "Epoch [10/50], Train Loss: 0.0099, Val Loss: 0.0117\n",
      "Validation loss decreased (0.011822 --> 0.011748).  Saving model ...\n",
      "Epoch [11/50], Loss: 0.0103\n",
      "Epoch [11/50], Train Loss: 0.0093, Val Loss: 0.0117\n",
      "Validation loss decreased (0.011748 --> 0.011671).  Saving model ...\n",
      "Epoch [12/50], Loss: 0.0143\n",
      "Epoch [12/50], Train Loss: 0.0107, Val Loss: 0.0114\n",
      "Validation loss decreased (0.011671 --> 0.011417).  Saving model ...\n",
      "Epoch [13/50], Loss: 0.0069\n",
      "Epoch [13/50], Train Loss: 0.0095, Val Loss: 0.0115\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch [14/50], Loss: 0.0055\n",
      "Epoch [14/50], Train Loss: 0.0125, Val Loss: 0.0120\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch [15/50], Loss: 0.0169\n",
      "Epoch [15/50], Train Loss: 0.0093, Val Loss: 0.0114\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch [16/50], Loss: 0.0044\n",
      "Epoch [16/50], Train Loss: 0.0110, Val Loss: 0.0112\n",
      "Validation loss decreased (0.011417 --> 0.011190).  Saving model ...\n",
      "Epoch [17/50], Loss: 0.0134\n",
      "Epoch [17/50], Train Loss: 0.0097, Val Loss: 0.0111\n",
      "Validation loss decreased (0.011190 --> 0.011068).  Saving model ...\n",
      "Epoch [18/50], Loss: 0.0131\n",
      "Epoch [18/50], Train Loss: 0.0090, Val Loss: 0.0109\n",
      "Validation loss decreased (0.011068 --> 0.010940).  Saving model ...\n",
      "Epoch [19/50], Loss: 0.0081\n",
      "Epoch [19/50], Train Loss: 0.0095, Val Loss: 0.0109\n",
      "Validation loss decreased (0.010940 --> 0.010879).  Saving model ...\n",
      "Epoch [20/50], Loss: 0.0162\n",
      "Epoch [20/50], Train Loss: 0.0092, Val Loss: 0.0108\n",
      "Validation loss decreased (0.010879 --> 0.010771).  Saving model ...\n",
      "Epoch [21/50], Loss: 0.0088\n",
      "Epoch [21/50], Train Loss: 0.0097, Val Loss: 0.0110\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch [22/50], Loss: 0.0096\n",
      "Epoch [22/50], Train Loss: 0.0093, Val Loss: 0.0110\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch [23/50], Loss: 0.0158\n",
      "Epoch [23/50], Train Loss: 0.0097, Val Loss: 0.0108\n",
      "Validation loss decreased (0.010771 --> 0.010765).  Saving model ...\n",
      "Epoch [24/50], Loss: 0.0020\n",
      "Epoch [24/50], Train Loss: 0.0101, Val Loss: 0.0111\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch [25/50], Loss: 0.0011\n",
      "Epoch [25/50], Train Loss: 0.0100, Val Loss: 0.0108\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch [26/50], Loss: 0.0090\n",
      "Epoch [26/50], Train Loss: 0.0110, Val Loss: 0.0112\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch [27/50], Loss: 0.0147\n",
      "Epoch [27/50], Train Loss: 0.0098, Val Loss: 0.0109\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch [28/50], Loss: 0.0012\n",
      "Epoch [28/50], Train Loss: 0.0094, Val Loss: 0.0106\n",
      "Validation loss decreased (0.010765 --> 0.010606).  Saving model ...\n",
      "Epoch [29/50], Loss: 0.0060\n",
      "Epoch [29/50], Train Loss: 0.0096, Val Loss: 0.0108\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch [30/50], Loss: 0.0054\n",
      "Epoch [30/50], Train Loss: 0.0096, Val Loss: 0.0111\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch [31/50], Loss: 0.0110\n",
      "Epoch [31/50], Train Loss: 0.0106, Val Loss: 0.0110\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch [32/50], Loss: 0.0002\n",
      "Epoch [32/50], Train Loss: 0.0123, Val Loss: 0.0110\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch [33/50], Loss: 0.0072\n",
      "Epoch [33/50], Train Loss: 0.0087, Val Loss: 0.0107\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch [34/50], Loss: 0.0161\n",
      "Epoch [34/50], Train Loss: 0.0085, Val Loss: 0.0107\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch [35/50], Loss: 0.0050\n",
      "Epoch [35/50], Train Loss: 0.0078, Val Loss: 0.0110\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch [36/50], Loss: 0.0014\n",
      "Epoch [36/50], Train Loss: 0.0095, Val Loss: 0.0106\n",
      "Validation loss decreased (0.010606 --> 0.010597).  Saving model ...\n",
      "Epoch [37/50], Loss: 0.0387\n",
      "Epoch [37/50], Train Loss: 0.0083, Val Loss: 0.0107\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch [38/50], Loss: 0.0108\n",
      "Epoch [38/50], Train Loss: 0.0095, Val Loss: 0.0109\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch [39/50], Loss: 0.0073\n",
      "Epoch [39/50], Train Loss: 0.0092, Val Loss: 0.0107\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch [40/50], Loss: 0.0033\n",
      "Epoch [40/50], Train Loss: 0.0101, Val Loss: 0.0107\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch [41/50], Loss: 0.0060\n",
      "Epoch [41/50], Train Loss: 0.0095, Val Loss: 0.0107\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch [42/50], Loss: 0.0034\n",
      "Epoch [42/50], Train Loss: 0.0111, Val Loss: 0.0115\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch [43/50], Loss: 0.0116\n",
      "Epoch [43/50], Train Loss: 0.0082, Val Loss: 0.0108\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch [44/50], Loss: 0.0259\n",
      "Epoch [44/50], Train Loss: 0.0089, Val Loss: 0.0108\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Epoch [45/50], Loss: 0.0109\n",
      "Epoch [45/50], Train Loss: 0.0090, Val Loss: 0.0107\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Epoch [46/50], Loss: 0.0048\n",
      "Epoch [46/50], Train Loss: 0.0096, Val Loss: 0.0110\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping triggered!\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 50\n",
    "val_interval = 1\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device).permute(0,2,1)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.view(-1,2), labels.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    train_losses.append(loss.item())\n",
    " \n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device).permute(0,2,1)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs.view(-1, 2), labels.view(-1))\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        val_losses.append(val_loss)\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')  # Save best model\n",
    "            print(\"Saving best model...\")\n",
    "        else:\n",
    "            early_stopping(val_loss, model)\n",
    "    \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a68278ed-237a-4cea-a914-6c5ee12bf0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the loss curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "#plt.plot([loss/len(train_loader) for loss in train_losses], label='Training Loss')\n",
    "#plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Curves')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97630fd4-2b76-424a-8f41-61cae6a2daf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TemporalConvNet.png'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "import torchviz\n",
    "# Dummy input for visualization\n",
    "dummy_input = torch.randn(1, 200, 1).to(device)  # [batch_size, seq_len, input_channels]\n",
    "dummy_input = dummy_input.permute(0, 2, 1)  # Match input format for Conv1d (B, C, L)\n",
    "\n",
    "# Forward pass\n",
    "output = model(dummy_input)\n",
    "\n",
    "# Generate and save visualization\n",
    "#graph = make_dot(output, params=dict(model.named_parameters()))\n",
    "dot = torchviz.make_dot(\n",
    "        output, \n",
    "        params=dict(model.named_parameters()),\n",
    "        show_attrs=False,  # Hide node attributes\n",
    "        show_saved=False   # Hide saved tensors\n",
    "    )\n",
    "simplify=True\n",
    "if simplify:\n",
    "        dot.graph_attr.update({\n",
    "            'rankdir': 'TB',    # Top to Bottom layout\n",
    "            'size': '8,5',      # Reduce overall graph size\n",
    "            'dpi': '300',       # Increase resolution\n",
    "        })\n",
    "        \n",
    "        # Reduce node complexity\n",
    "        dot.node_attr.update({\n",
    "            'shape': 'box',     # Simpler node shape\n",
    "            'style': 'filled',  # Fill color\n",
    "            'fillcolor': 'lightblue',  # Light background\n",
    "            'fontsize': '10',   # Smaller font\n",
    "        })\n",
    "        \n",
    "        # Reduce edge complexity\n",
    "        dot.edge_attr.update({\n",
    "            'color': 'gray',    # Muted edge color\n",
    "            'penwidth': '0.5',  # Thinner edges\n",
    "        })\n",
    "dot.render(\"TemporalConvNet\", format=\"png\")  # Save as PNG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796b3063-46a3-448a-a0f6-44e4cbe4ec39",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd3d5e20-55c8-4abf-824e-767a0f281049",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    \"\"\"Evaluates the model and computes various metrics.\"\"\"\n",
    "    model.eval()\n",
    "    all_true_labels = []\n",
    "    all_predicted_labels = []\n",
    "    all_probabilities = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            #outputs = model(inputs.permute(0,2,1))\n",
    "            loss = criterion(outputs.view(-1, 2), labels.view(-1))\n",
    "            test_loss += loss.item()\n",
    "            probabilities = torch.softmax(outputs, dim=2) #Softmax to get probabilities\n",
    "            threshold = 0.5325 # Example: Lower threshold\n",
    "            predicted = (probabilities[:, :, 1] > threshold).long()\n",
    "            #_, predicted = torch.max(outputs.data, 2)\n",
    "\n",
    "            all_true_labels.extend(labels.view(-1).cpu().numpy())\n",
    "            all_predicted_labels.extend(predicted.view(-1).cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.view(-1,2).cpu().numpy())\n",
    "            total += labels.view(-1).size(0)\n",
    "            correct += (predicted.view(-1) == labels.view(-1)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    # Calculate metrics\n",
    "    accuracy=100 * correct / total\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_true_labels, all_predicted_labels, average=\"binary\", zero_division=0\n",
    "    )\n",
    "    try:\n",
    "        auc = roc_auc_score(all_true_labels, np.array(all_probabilities)[:, 1]) #Calculate AUC\n",
    "    except ValueError:\n",
    "        auc = np.nan\n",
    "        print(\"Only one class present in y_true. ROC AUC score is not defined in that case.\")\n",
    "\n",
    "    probabilities_positive_class = np.array(all_probabilities)[:, 1]  # Probability of the positive class\n",
    "    precision_curve, recall_curve, thresholds = precision_recall_curve(all_true_labels, probabilities_positive_class)\n",
    "    f1_scores = 2 * (precision_curve * recall_curve) / (precision_curve + recall_curve + 1e-10)  # F1 for each threshold\n",
    "    best_threshold = thresholds[np.argmax(f1_scores)]  # Optimal threshold\n",
    "    best_f1_score = np.max(f1_scores)\n",
    "\n",
    "    print(f\"Optimal Threshold: {best_threshold:.4f}\")\n",
    "    print(f\"Best F1-Score at Optimal Threshold: {best_f1_score:.4f}\")\n",
    "    \n",
    "    return precision, recall, f1, auc, accuracy,best_f1_score,best_threshold,test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e467c4ed-f85d-471b-b31a-7e82c03d648e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniforge3/lib/python3.9/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.0054\n",
      "Epoch [1/100], Train Loss: 0.0460, Val Loss: 0.0420\n",
      "Saving best Transformer model...\n",
      "Epoch [2/100], Loss: 0.0026\n",
      "Epoch [2/100], Train Loss: 0.0322, Val Loss: 0.0310\n",
      "Saving best Transformer model...\n",
      "Epoch [3/100], Loss: 0.1305\n",
      "Epoch [3/100], Train Loss: 0.0291, Val Loss: 0.0273\n",
      "Saving best Transformer model...\n",
      "Epoch [4/100], Loss: 0.0015\n",
      "Epoch [4/100], Train Loss: 0.0230, Val Loss: 0.0228\n",
      "Saving best Transformer model...\n",
      "Epoch [5/100], Loss: 0.0002\n",
      "Epoch [5/100], Train Loss: 0.0210, Val Loss: 0.0212\n",
      "Saving best Transformer model...\n",
      "Epoch [6/100], Loss: 0.0002\n",
      "Epoch [6/100], Train Loss: 0.0194, Val Loss: 0.0207\n",
      "Saving best Transformer model...\n",
      "Epoch [7/100], Loss: 0.0001\n",
      "Epoch [7/100], Train Loss: 0.0195, Val Loss: 0.0199\n",
      "Saving best Transformer model...\n",
      "Epoch [8/100], Loss: 0.0850\n",
      "Epoch [8/100], Train Loss: 0.0194, Val Loss: 0.0204\n",
      "Validation loss decreased (inf --> 0.020416).  Saving model ...\n",
      "Epoch [9/100], Loss: 0.0002\n",
      "Epoch [9/100], Train Loss: 0.0197, Val Loss: 0.0201\n",
      "Validation loss decreased (0.020416 --> 0.020106).  Saving model ...\n",
      "Epoch [10/100], Loss: 0.1311\n",
      "Epoch [10/100], Train Loss: 0.0187, Val Loss: 0.0195\n",
      "Saving best Transformer model...\n",
      "Epoch [11/100], Loss: 0.0001\n",
      "Epoch [11/100], Train Loss: 0.0185, Val Loss: 0.0194\n",
      "Saving best Transformer model...\n",
      "Epoch [12/100], Loss: 0.0444\n",
      "Epoch [12/100], Train Loss: 0.0197, Val Loss: 0.0202\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch [13/100], Loss: 0.0001\n",
      "Epoch [13/100], Train Loss: 0.0185, Val Loss: 0.0194\n",
      "Validation loss decreased (0.020106 --> 0.019407).  Saving model ...\n",
      "Epoch [14/100], Loss: 0.0001\n",
      "Epoch [14/100], Train Loss: 0.0190, Val Loss: 0.0196\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch [15/100], Loss: 0.0004\n",
      "Epoch [15/100], Train Loss: 0.0188, Val Loss: 0.0192\n",
      "Saving best Transformer model...\n",
      "Epoch [16/100], Loss: 0.0001\n",
      "Epoch [16/100], Train Loss: 0.0196, Val Loss: 0.0191\n",
      "Saving best Transformer model...\n",
      "Epoch [17/100], Loss: 0.0000\n",
      "Epoch [17/100], Train Loss: 0.0186, Val Loss: 0.0191\n",
      "Saving best Transformer model...\n",
      "Epoch [18/100], Loss: 0.0000\n",
      "Epoch [18/100], Train Loss: 0.0186, Val Loss: 0.0189\n",
      "Saving best Transformer model...\n",
      "Epoch [19/100], Loss: 0.0856\n",
      "Epoch [19/100], Train Loss: 0.0182, Val Loss: 0.0190\n",
      "Validation loss decreased (0.019407 --> 0.019018).  Saving model ...\n",
      "Epoch [20/100], Loss: 0.0016\n",
      "Epoch [20/100], Train Loss: 0.0196, Val Loss: 0.0182\n",
      "Saving best Transformer model...\n",
      "Epoch [21/100], Loss: 0.0000\n",
      "Epoch [21/100], Train Loss: 0.0193, Val Loss: 0.0182\n",
      "Validation loss decreased (0.019018 --> 0.018216).  Saving model ...\n",
      "Epoch [22/100], Loss: 0.0001\n",
      "Epoch [22/100], Train Loss: 0.0183, Val Loss: 0.0179\n",
      "Saving best Transformer model...\n",
      "Epoch [23/100], Loss: 0.0000\n",
      "Epoch [23/100], Train Loss: 0.0190, Val Loss: 0.0173\n",
      "Saving best Transformer model...\n",
      "Epoch [24/100], Loss: 0.0000\n",
      "Epoch [24/100], Train Loss: 0.0187, Val Loss: 0.0173\n",
      "Saving best Transformer model...\n",
      "Epoch [25/100], Loss: 0.0001\n",
      "Epoch [25/100], Train Loss: 0.0167, Val Loss: 0.0167\n",
      "Saving best Transformer model...\n",
      "Epoch [26/100], Loss: 0.0000\n",
      "Epoch [26/100], Train Loss: 0.0162, Val Loss: 0.0163\n",
      "Saving best Transformer model...\n",
      "Epoch [27/100], Loss: 0.0000\n",
      "Epoch [27/100], Train Loss: 0.0156, Val Loss: 0.0161\n",
      "Saving best Transformer model...\n",
      "Epoch [28/100], Loss: 0.0000\n",
      "Epoch [28/100], Train Loss: 0.0141, Val Loss: 0.0158\n",
      "Saving best Transformer model...\n",
      "Epoch [29/100], Loss: 0.0000\n",
      "Epoch [29/100], Train Loss: 0.0135, Val Loss: 0.0153\n",
      "Saving best Transformer model...\n",
      "Epoch [30/100], Loss: 0.0502\n",
      "Epoch [30/100], Train Loss: 0.0131, Val Loss: 0.0158\n",
      "Validation loss decreased (0.018216 --> 0.015768).  Saving model ...\n",
      "Epoch [31/100], Loss: 0.0000\n",
      "Epoch [31/100], Train Loss: 0.0127, Val Loss: 0.0153\n",
      "Saving best Transformer model...\n",
      "Epoch [32/100], Loss: 0.0000\n",
      "Epoch [32/100], Train Loss: 0.0120, Val Loss: 0.0153\n",
      "Validation loss decreased (0.015768 --> 0.015327).  Saving model ...\n",
      "Epoch [33/100], Loss: 0.0000\n",
      "Epoch [33/100], Train Loss: 0.0098, Val Loss: 0.0143\n",
      "Saving best Transformer model...\n",
      "Epoch [34/100], Loss: 0.0000\n",
      "Epoch [34/100], Train Loss: 0.0098, Val Loss: 0.0145\n",
      "Validation loss decreased (0.015327 --> 0.014548).  Saving model ...\n",
      "Epoch [35/100], Loss: 0.0004\n",
      "Epoch [35/100], Train Loss: 0.0094, Val Loss: 0.0146\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch [36/100], Loss: 0.0000\n",
      "Epoch [36/100], Train Loss: 0.0090, Val Loss: 0.0142\n",
      "Saving best Transformer model...\n",
      "Epoch [37/100], Loss: 0.0000\n",
      "Epoch [37/100], Train Loss: 0.0085, Val Loss: 0.0133\n",
      "Saving best Transformer model...\n",
      "Epoch [38/100], Loss: 0.0000\n",
      "Epoch [38/100], Train Loss: 0.0092, Val Loss: 0.0133\n",
      "Validation loss decreased (0.014548 --> 0.013346).  Saving model ...\n",
      "Epoch [39/100], Loss: 0.0000\n",
      "Epoch [39/100], Train Loss: 0.0078, Val Loss: 0.0132\n",
      "Saving best Transformer model...\n",
      "Epoch [40/100], Loss: 0.0000\n",
      "Epoch [40/100], Train Loss: 0.0072, Val Loss: 0.0130\n",
      "Saving best Transformer model...\n",
      "Epoch [41/100], Loss: 0.0001\n",
      "Epoch [41/100], Train Loss: 0.0071, Val Loss: 0.0125\n",
      "Saving best Transformer model...\n",
      "Epoch [42/100], Loss: 0.0016\n",
      "Epoch [42/100], Train Loss: 0.0066, Val Loss: 0.0125\n",
      "Validation loss decreased (0.013346 --> 0.012523).  Saving model ...\n",
      "Epoch [43/100], Loss: 0.0001\n",
      "Epoch [43/100], Train Loss: 0.0062, Val Loss: 0.0121\n",
      "Saving best Transformer model...\n",
      "Epoch [44/100], Loss: 0.0000\n",
      "Epoch [44/100], Train Loss: 0.0057, Val Loss: 0.0120\n",
      "Saving best Transformer model...\n",
      "Epoch [45/100], Loss: 0.0000\n",
      "Epoch [45/100], Train Loss: 0.0053, Val Loss: 0.0118\n",
      "Saving best Transformer model...\n",
      "Epoch [46/100], Loss: 0.0001\n",
      "Epoch [46/100], Train Loss: 0.0049, Val Loss: 0.0116\n",
      "Saving best Transformer model...\n",
      "Epoch [47/100], Loss: 0.0183\n",
      "Epoch [47/100], Train Loss: 0.0048, Val Loss: 0.0115\n",
      "Saving best Transformer model...\n",
      "Epoch [48/100], Loss: 0.0000\n",
      "Epoch [48/100], Train Loss: 0.0048, Val Loss: 0.0110\n",
      "Saving best Transformer model...\n",
      "Epoch [49/100], Loss: 0.0000\n",
      "Epoch [49/100], Train Loss: 0.0043, Val Loss: 0.0109\n",
      "Saving best Transformer model...\n",
      "Epoch [50/100], Loss: 0.0277\n",
      "Epoch [50/100], Train Loss: 0.0043, Val Loss: 0.0109\n",
      "Validation loss decreased (0.012523 --> 0.010866).  Saving model ...\n",
      "Epoch [51/100], Loss: 0.0414\n",
      "Epoch [51/100], Train Loss: 0.0043, Val Loss: 0.0104\n",
      "Saving best Transformer model...\n",
      "Epoch [52/100], Loss: 0.0001\n",
      "Epoch [52/100], Train Loss: 0.0043, Val Loss: 0.0100\n",
      "Saving best Transformer model...\n",
      "Epoch [53/100], Loss: 0.0000\n",
      "Epoch [53/100], Train Loss: 0.0037, Val Loss: 0.0100\n",
      "Validation loss decreased (0.010866 --> 0.009999).  Saving model ...\n",
      "Epoch [54/100], Loss: 0.0000\n",
      "Epoch [54/100], Train Loss: 0.0042, Val Loss: 0.0099\n",
      "Saving best Transformer model...\n",
      "Epoch [55/100], Loss: 0.0000\n",
      "Epoch [55/100], Train Loss: 0.0038, Val Loss: 0.0100\n",
      "Validation loss decreased (0.009999 --> 0.009990).  Saving model ...\n",
      "Epoch [56/100], Loss: 0.0000\n",
      "Epoch [56/100], Train Loss: 0.0042, Val Loss: 0.0099\n",
      "Saving best Transformer model...\n",
      "Epoch [57/100], Loss: 0.0000\n",
      "Epoch [57/100], Train Loss: 0.0037, Val Loss: 0.0096\n",
      "Saving best Transformer model...\n",
      "Epoch [58/100], Loss: 0.0000\n",
      "Epoch [58/100], Train Loss: 0.0034, Val Loss: 0.0090\n",
      "Saving best Transformer model...\n",
      "Epoch [59/100], Loss: 0.0000\n",
      "Epoch [59/100], Train Loss: 0.0033, Val Loss: 0.0090\n",
      "Validation loss decreased (0.009990 --> 0.008971).  Saving model ...\n",
      "Epoch [60/100], Loss: 0.0002\n",
      "Epoch [60/100], Train Loss: 0.0032, Val Loss: 0.0088\n",
      "Saving best Transformer model...\n",
      "Epoch [61/100], Loss: 0.0000\n",
      "Epoch [61/100], Train Loss: 0.0036, Val Loss: 0.0092\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch [62/100], Loss: 0.0001\n",
      "Epoch [62/100], Train Loss: 0.0030, Val Loss: 0.0092\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch [63/100], Loss: 0.0000\n",
      "Epoch [63/100], Train Loss: 0.0031, Val Loss: 0.0087\n",
      "Saving best Transformer model...\n",
      "Epoch [64/100], Loss: 0.0000\n",
      "Epoch [64/100], Train Loss: 0.0032, Val Loss: 0.0089\n",
      "Validation loss decreased (0.008971 --> 0.008858).  Saving model ...\n",
      "Epoch [65/100], Loss: 0.0000\n",
      "Epoch [65/100], Train Loss: 0.0028, Val Loss: 0.0085\n",
      "Saving best Transformer model...\n",
      "Epoch [66/100], Loss: 0.0000\n",
      "Epoch [66/100], Train Loss: 0.0032, Val Loss: 0.0082\n",
      "Saving best Transformer model...\n",
      "Epoch [67/100], Loss: 0.1584\n",
      "Epoch [67/100], Train Loss: 0.0030, Val Loss: 0.0086\n",
      "Validation loss decreased (0.008858 --> 0.008607).  Saving model ...\n",
      "Epoch [68/100], Loss: 0.0000\n",
      "Epoch [68/100], Train Loss: 0.0029, Val Loss: 0.0086\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch [69/100], Loss: 0.0000\n",
      "Epoch [69/100], Train Loss: 0.0027, Val Loss: 0.0082\n",
      "Validation loss decreased (0.008607 --> 0.008225).  Saving model ...\n",
      "Epoch [70/100], Loss: 0.0001\n",
      "Epoch [70/100], Train Loss: 0.0027, Val Loss: 0.0083\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch [71/100], Loss: 0.0000\n",
      "Epoch [71/100], Train Loss: 0.0027, Val Loss: 0.0080\n",
      "Saving best Transformer model...\n",
      "Epoch [72/100], Loss: 0.0428\n",
      "Epoch [72/100], Train Loss: 0.0029, Val Loss: 0.0085\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch [73/100], Loss: 0.0000\n",
      "Epoch [73/100], Train Loss: 0.0029, Val Loss: 0.0082\n",
      "Validation loss decreased (0.008225 --> 0.008165).  Saving model ...\n",
      "Epoch [74/100], Loss: 0.0000\n",
      "Epoch [74/100], Train Loss: 0.0026, Val Loss: 0.0082\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch [75/100], Loss: 0.0000\n",
      "Epoch [75/100], Train Loss: 0.0027, Val Loss: 0.0082\n",
      "Validation loss decreased (0.008165 --> 0.008161).  Saving model ...\n",
      "Epoch [76/100], Loss: 0.0000\n",
      "Epoch [76/100], Train Loss: 0.0026, Val Loss: 0.0081\n",
      "Validation loss decreased (0.008161 --> 0.008144).  Saving model ...\n",
      "Epoch [77/100], Loss: 0.0028\n",
      "Epoch [77/100], Train Loss: 0.0026, Val Loss: 0.0081\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch [78/100], Loss: 0.0000\n",
      "Epoch [78/100], Train Loss: 0.0026, Val Loss: 0.0081\n",
      "Validation loss decreased (0.008144 --> 0.008101).  Saving model ...\n",
      "Epoch [79/100], Loss: 0.0073\n",
      "Epoch [79/100], Train Loss: 0.0026, Val Loss: 0.0079\n",
      "Saving best Transformer model...\n",
      "Epoch [80/100], Loss: 0.0000\n",
      "Epoch [80/100], Train Loss: 0.0025, Val Loss: 0.0079\n",
      "Validation loss decreased (0.008101 --> 0.007858).  Saving model ...\n",
      "Epoch [81/100], Loss: 0.0000\n",
      "Epoch [81/100], Train Loss: 0.0026, Val Loss: 0.0082\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch [82/100], Loss: 0.1733\n",
      "Epoch [82/100], Train Loss: 0.0025, Val Loss: 0.0079\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch [83/100], Loss: 0.0000\n",
      "Epoch [83/100], Train Loss: 0.0025, Val Loss: 0.0079\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch [84/100], Loss: 0.0040\n",
      "Epoch [84/100], Train Loss: 0.0025, Val Loss: 0.0078\n",
      "Saving best Transformer model...\n",
      "Epoch [85/100], Loss: 0.0002\n",
      "Epoch [85/100], Train Loss: 0.0025, Val Loss: 0.0079\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch [86/100], Loss: 0.0000\n",
      "Epoch [86/100], Train Loss: 0.0025, Val Loss: 0.0080\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch [87/100], Loss: 0.0000\n",
      "Epoch [87/100], Train Loss: 0.0025, Val Loss: 0.0079\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch [88/100], Loss: 0.0007\n",
      "Epoch [88/100], Train Loss: 0.0025, Val Loss: 0.0079\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch [89/100], Loss: 0.0000\n",
      "Epoch [89/100], Train Loss: 0.0025, Val Loss: 0.0079\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch [90/100], Loss: 0.0000\n",
      "Epoch [90/100], Train Loss: 0.0025, Val Loss: 0.0078\n",
      "Validation loss decreased (0.007858 --> 0.007846).  Saving model ...\n",
      "Epoch [91/100], Loss: 0.0000\n",
      "Epoch [91/100], Train Loss: 0.0025, Val Loss: 0.0080\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch [92/100], Loss: 0.0000\n",
      "Epoch [92/100], Train Loss: 0.0025, Val Loss: 0.0079\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch [93/100], Loss: 0.0219\n",
      "Epoch [93/100], Train Loss: 0.0025, Val Loss: 0.0079\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch [94/100], Loss: 0.0491\n",
      "Epoch [94/100], Train Loss: 0.0025, Val Loss: 0.0080\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch [95/100], Loss: 0.0013\n",
      "Epoch [95/100], Train Loss: 0.0025, Val Loss: 0.0079\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch [96/100], Loss: 0.0000\n",
      "Epoch [96/100], Train Loss: 0.0025, Val Loss: 0.0080\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch [97/100], Loss: 0.0000\n",
      "Epoch [97/100], Train Loss: 0.0025, Val Loss: 0.0080\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch [98/100], Loss: 0.0000\n",
      "Epoch [98/100], Train Loss: 0.0025, Val Loss: 0.0080\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch [99/100], Loss: 0.0604\n",
      "Epoch [99/100], Train Loss: 0.0025, Val Loss: 0.0080\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch [100/100], Loss: 0.0000\n",
      "Epoch [100/100], Train Loss: 0.0025, Val Loss: 0.0080\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Test Loss: 0.0077\n",
      "Optimal Threshold: 0.3414\n",
      "Best F1-Score at Optimal Threshold: 0.8178\n",
      "Accuracy of the Transformer model on the test set: 99.70%\n",
      "Precision: 0.8674\n",
      "Recall: 0.7413\n",
      "F1-score: 0.7994\n",
      "AUC: 0.9988\n"
     ]
    }
   ],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, d_model, nhead, num_encoder_layers, dim_feedforward, output_size, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, d_model)  # Linear layer to match input to model dimension\n",
    "        self.positional_encoding = nn.Parameter(torch.randn(1, 1000, d_model))  # Learnable positional encodings\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout),\n",
    "            num_layers=num_encoder_layers,\n",
    "        )\n",
    "        self.fc = nn.Linear(d_model, output_size)  # Fully connected layer for final predictions\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = x + self.positional_encoding[:, :x.size(1), :]  # Add positional encoding\n",
    "        x = self.transformer(x.permute(1, 0, 2))  # Transformer expects (seq_len, batch_size, d_model)\n",
    "        x = x.permute(1, 0, 2)  # Back to (batch_size, seq_len, d_model)\n",
    "        x = self.fc(x)  # Fully connected layer for classification\n",
    "        return x\n",
    "\n",
    "\n",
    "# Model parameters\n",
    "d_model = 64 # Model dimension\n",
    "nhead = 4 # Number of attention heads\n",
    "num_encoder_layers = 6 # Number of transformer encoder layers\n",
    "dim_feedforward = 256 # Feedforward dimension\n",
    "output_size = 2  # Binary classification for each timestep\n",
    "num_epochs = 100\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize Transformer model\n",
    "transformer_model = TransformerModel(\n",
    "    input_size=1, d_model=d_model, nhead=nhead,\n",
    "    num_encoder_layers=num_encoder_layers,\n",
    "    dim_feedforward=dim_feedforward, output_size=output_size,\n",
    "    dropout=0.1 \n",
    ").to(device)\n",
    "\n",
    "# Loss, optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(transformer_model.parameters(), lr=0.0001, weight_decay=1e-4)  # Lower LR and add weight decay\n",
    "\n",
    "early_stopping = EarlyStopping(patience=30, verbose=True)\n",
    "\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=len(train_loader) * 5,  # Warmup steps\n",
    "    num_training_steps=len(train_loader) * num_epochs,  # Total training steps\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "val_interval = 1\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    transformer_model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = transformer_model(inputs)\n",
    "        loss = criterion(outputs.view(-1, output_size), labels.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    train_losses.append(loss.item())\n",
    "    \n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        transformer_model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = transformer_model(inputs)\n",
    "                loss = criterion(outputs.view(-1, output_size), labels.view(-1))\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        val_losses.append(val_loss)\n",
    "    \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(transformer_model.state_dict(), 'best_transformer_model.pth')  # Save best model\n",
    "            print(\"Saving best Transformer model...\")\n",
    "        else:\n",
    "            early_stopping(val_loss, transformer_model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "# Evaluate model\n",
    "precision, recall, f1, auc, accuracy, best_f1, best_thresh, test_loss = evaluate_model(transformer_model, test_loader, device)\n",
    "print(f'Accuracy of the Transformer model on the test set: {accuracy:.2f}%')\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43e92799-0be5-46bb-b6db-a7e607e97d57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing combination: {'d_model': 64, 'nhead': 4, 'num_encoder_layers': 3, 'dim_feedforward': 256, 'dropout': 0.1, 'lr': 0.0005, 'weight_decay': 0.0001, 'num_epochs': 50, 'val_interval': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniforge3/lib/python3.9/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Test Loss: 0.0061\n",
      "Optimal Threshold: 0.4537\n",
      "Best F1-Score at Optimal Threshold: 0.8488\n",
      "F1 Score for current combination: 0.8488\n",
      "New best F1 Score: 0.8488 with params: {'d_model': 64, 'nhead': 4, 'num_encoder_layers': 3, 'dim_feedforward': 256, 'dropout': 0.1, 'lr': 0.0005, 'weight_decay': 0.0001, 'num_epochs': 50, 'val_interval': 1}\n",
      "Testing combination: {'d_model': 64, 'nhead': 4, 'num_encoder_layers': 6, 'dim_feedforward': 256, 'dropout': 0.1, 'lr': 0.0005, 'weight_decay': 0.0001, 'num_epochs': 50, 'val_interval': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniforge3/lib/python3.9/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Test Loss: 0.0058\n",
      "Optimal Threshold: 0.5033\n",
      "Best F1-Score at Optimal Threshold: 0.8660\n",
      "F1 Score for current combination: 0.8660\n",
      "New best F1 Score: 0.8660 with params: {'d_model': 64, 'nhead': 4, 'num_encoder_layers': 6, 'dim_feedforward': 256, 'dropout': 0.1, 'lr': 0.0005, 'weight_decay': 0.0001, 'num_epochs': 50, 'val_interval': 1}\n",
      "Testing combination: {'d_model': 64, 'nhead': 8, 'num_encoder_layers': 3, 'dim_feedforward': 256, 'dropout': 0.1, 'lr': 0.0005, 'weight_decay': 0.0001, 'num_epochs': 50, 'val_interval': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniforge3/lib/python3.9/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Test Loss: 0.0063\n",
      "Optimal Threshold: 0.4263\n",
      "Best F1-Score at Optimal Threshold: 0.8428\n",
      "F1 Score for current combination: 0.8428\n",
      "Testing combination: {'d_model': 64, 'nhead': 8, 'num_encoder_layers': 6, 'dim_feedforward': 256, 'dropout': 0.1, 'lr': 0.0005, 'weight_decay': 0.0001, 'num_epochs': 50, 'val_interval': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniforge3/lib/python3.9/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Test Loss: 0.0059\n",
      "Optimal Threshold: 0.3986\n",
      "Best F1-Score at Optimal Threshold: 0.8611\n",
      "F1 Score for current combination: 0.8611\n",
      "Testing combination: {'d_model': 128, 'nhead': 4, 'num_encoder_layers': 3, 'dim_feedforward': 256, 'dropout': 0.1, 'lr': 0.0005, 'weight_decay': 0.0001, 'num_epochs': 50, 'val_interval': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniforge3/lib/python3.9/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Test Loss: 0.0070\n",
      "Optimal Threshold: 0.4187\n",
      "Best F1-Score at Optimal Threshold: 0.8401\n",
      "F1 Score for current combination: 0.8401\n",
      "Testing combination: {'d_model': 128, 'nhead': 4, 'num_encoder_layers': 6, 'dim_feedforward': 256, 'dropout': 0.1, 'lr': 0.0005, 'weight_decay': 0.0001, 'num_epochs': 50, 'val_interval': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniforge3/lib/python3.9/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Test Loss: 0.0066\n",
      "Optimal Threshold: 0.4171\n",
      "Best F1-Score at Optimal Threshold: 0.8529\n",
      "F1 Score for current combination: 0.8529\n",
      "Testing combination: {'d_model': 128, 'nhead': 8, 'num_encoder_layers': 3, 'dim_feedforward': 256, 'dropout': 0.1, 'lr': 0.0005, 'weight_decay': 0.0001, 'num_epochs': 50, 'val_interval': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniforge3/lib/python3.9/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Test Loss: 0.0069\n",
      "Optimal Threshold: 0.4644\n",
      "Best F1-Score at Optimal Threshold: 0.8494\n",
      "F1 Score for current combination: 0.8494\n",
      "Testing combination: {'d_model': 128, 'nhead': 8, 'num_encoder_layers': 6, 'dim_feedforward': 256, 'dropout': 0.1, 'lr': 0.0005, 'weight_decay': 0.0001, 'num_epochs': 50, 'val_interval': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniforge3/lib/python3.9/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Test Loss: 0.0066\n",
      "Optimal Threshold: 0.4419\n",
      "Best F1-Score at Optimal Threshold: 0.8602\n",
      "F1 Score for current combination: 0.8602\n",
      "Best F1 Score by Grid Search: 0.8660318419491941\n",
      "Best Hyperparameters: {'d_model': 64, 'nhead': 4, 'num_encoder_layers': 6, 'dim_feedforward': 256, 'dropout': 0.1, 'lr': 0.0005, 'weight_decay': 0.0001, 'num_epochs': 50, 'val_interval': 1}\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def grid_search_transformer(params, train_loader, val_loader, test_loader, device):\n",
    "    best_f1 = 0\n",
    "    best_params = None\n",
    "    \n",
    "    # Iterate over all combinations of hyperparameters\n",
    "    for combination in itertools.product(*params.values()):\n",
    "        hyperparams = dict(zip(params.keys(), combination))\n",
    "        print(f\"Testing combination: {hyperparams}\")\n",
    "        \n",
    "        # Initialize the Transformer model with the current set of hyperparameters\n",
    "        transformer_model = TransformerModel(\n",
    "            input_size=1, \n",
    "            d_model=hyperparams['d_model'], \n",
    "            nhead=hyperparams['nhead'],\n",
    "            num_encoder_layers=hyperparams['num_encoder_layers'],\n",
    "            dim_feedforward=hyperparams['dim_feedforward'],\n",
    "            output_size=2, \n",
    "            dropout=hyperparams['dropout']\n",
    "        ).to(device)\n",
    "\n",
    "        # Loss, optimizer, and scheduler\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.AdamW(\n",
    "            transformer_model.parameters(), \n",
    "            lr=hyperparams['lr'], \n",
    "            weight_decay=hyperparams['weight_decay']\n",
    "        )\n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=len(train_loader) * 5,\n",
    "            num_training_steps=len(train_loader) * hyperparams['num_epochs'],\n",
    "        )\n",
    "\n",
    "        # Training loop\n",
    "        early_stopping = EarlyStopping(patience=10, verbose=False)\n",
    "        for epoch in range(hyperparams['num_epochs']):\n",
    "            transformer_model.train()\n",
    "            for inputs, labels in train_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = transformer_model(inputs)\n",
    "                loss = criterion(outputs.view(-1, 2), labels.view(-1))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "            # Validate model\n",
    "            if (epoch + 1) % hyperparams['val_interval'] == 0:\n",
    "                transformer_model.eval()\n",
    "                val_loss = 0.0\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in val_loader:\n",
    "                        inputs, labels = inputs.to(device), labels.to(device)\n",
    "                        outputs = transformer_model(inputs)\n",
    "                        loss = criterion(outputs.view(-1, 2), labels.view(-1))\n",
    "                        val_loss += loss.item()\n",
    "                val_loss /= len(val_loader)\n",
    "                early_stopping(val_loss, transformer_model)\n",
    "\n",
    "                if early_stopping.early_stop:\n",
    "                    break\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        precision, recall, f1, auc, accuracy, bf1, _, _ = evaluate_model(transformer_model, test_loader, device)\n",
    "        print(f\"F1 Score for current combination: {bf1:.4f}\")\n",
    "\n",
    "        # Update best parameters if current F1 is better\n",
    "        if bf1 > best_f1:\n",
    "            best_f1 = bf1\n",
    "            best_params = hyperparams\n",
    "            print(f\"New best F1 Score: {best_f1:.4f} with params: {best_params}\")\n",
    "    \n",
    "    return {'best_f1': best_f1, 'best_params': best_params}\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'd_model': [64, 128],  # Cover two distinct model dimensions.\n",
    "    'nhead': [4, 8],  # Lower and higher attention heads.\n",
    "    'num_encoder_layers': [3, 6],  # Fewer vs. more layers.\n",
    "    'dim_feedforward': [256],  # Set to the higher value since it's computationally feasible.\n",
    "    'dropout': [0.1],  # Use a single value to simplify.\n",
    "    'lr': [0.0005],  # Single value based on good performance in your initial runs.\n",
    "    'weight_decay': [1e-4],  # Use a single, effective value.\n",
    "    'num_epochs': [50],  # Shorter runs to balance exploration.\n",
    "    'val_interval': [1]  # Leave unchanged for frequent validation.\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "results = grid_search_transformer(param_grid, train_loader, val_loader, test_loader, device)\n",
    "\n",
    "print(f\"Best F1 Score by Grid Search: {results['best_f1']}\")\n",
    "print(f\"Best Hyperparameters: {results['best_params']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_midsem",
   "language": "python",
   "name": "dl_midsem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
